name: "w2v2"
platform: "onnxruntime_onnx"
max_batch_size: 16
input [
  {
    name: "INPUT__0"
    data_type: TYPE_FP32
    dims: [ -1 ]
  }
]
output [
  {
    name: "OUTPUT__0"
    data_type: TYPE_FP32
    dims: [ -1, -1 ]
  }
]
instance_group [{ kind: KIND_GPU }]
dynamic_batching { preferred_batch_size: [ 8, 16 ] max_queue_delay_microseconds: 5000 }
